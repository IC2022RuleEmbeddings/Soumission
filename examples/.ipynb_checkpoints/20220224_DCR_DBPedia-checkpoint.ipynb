{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "- Propose a tutorial on how to use our library to mine differential causal rules on Knowledge Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 : Imports and Parameters Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmpliGraph version OK\n",
      "TensorFlow version OK\n"
     ]
    }
   ],
   "source": [
    "import ampligraph\n",
    "import tensorflow as tf\n",
    "\n",
    "if ampligraph.__version__ == '1.4.0':\n",
    "    print(\"AmpliGraph version OK\")\n",
    "if tf.__version__ == '1.15.2':\n",
    "    print(\"TensorFlow version OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.datasets import load_from_csv\n",
    "from ampligraph.evaluation import train_test_split_no_unseen\n",
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "from ampligraph.evaluation import evaluate_performance\n",
    "from ampligraph.latent_features.models import ConvE, DistMult, ComplEx, TransE, RandomBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../similarity_search')\n",
    "from pairs_mining import *\n",
    "from threshold_estimation import *\n",
    "from distance_threshold_estimation import *\n",
    "sys.path.append('../dcr_discovery')\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '../datasets'\n",
    "file_name = 'dbpedia_extract.csv'\n",
    "X = load_from_csv(directory_path,file_name, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The knowledge graph is composed of 6908 triples\n"
     ]
    }
   ],
   "source": [
    "# checking the import\n",
    "print(f\"The knowledge graph is composed of {len(X)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = list(np.unique([x[1] for x in X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_bug = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_try = [x for x in X if x[1] not in relations_bug]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement marche :\n",
    "- avec ancienne version\n",
    "- sans les 3 modifications\n",
    "- avec birthDate\n",
    "- avec arwuW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement marche PAS :\n",
    "- avec les 3\n",
    "- avec endowment\n",
    "- avec arwuW ET birthDate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TYPE = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'\n",
    "TYPE_TARGET_CLASS = 'http://dbpedia.org/ontology/Writer'\n",
    "\n",
    "PATH_TREATMENT = []\n",
    "PATH_OUTCOME = ['http://dbpedia.org/ontology/releaseDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SET_PROPORTION = 0.1\n",
    "\n",
    "SAMPLING_PARAMETER = 20\n",
    "STAT_PARAM = 1.96\n",
    "SUPPORT_THRESHOLD = 10\n",
    "SIMILARITY_THRESHOLD = 0.75\n",
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 : Embedding Model - Training sets Definition, Training and Metrics\n",
    "\n",
    "- For this example, we decide to train the ConvE model\n",
    "- However, we recommand the reader to visit the ampligraph library to test other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_before_sub = len(X_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec subsampling\n",
    "X_try = [x for x in X_try if random.random() > 0.15]\n",
    "size_after_sub = len(X_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.150839606253619\n"
     ]
    }
   ],
   "source": [
    "print((size_before_sub-size_after_sub)/size_before_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = np.array(X_try)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# avec dataset COMPLET\n",
    "X_training = np.array(X_try)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ConvE, DistMult, ComplEx, TransE, RandomBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training sets\n",
    "# X_training = np.array([x for x in X if x[1] not in PATHS_TO_REMOVE_IN_TRAINING])\n",
    "\n",
    "test_size = round(TEST_SET_PROPORTION*len(X_training))\n",
    "X_train, X_test = train_test_split_no_unseen(X_training, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_filter = X_training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# defining the model\n",
    "model_name = 'ConvE'\n",
    "model = ConvE(batches_count=100, \n",
    "              seed=555, \n",
    "              epochs=EPOCHS, \n",
    "              k=150,\n",
    "              eta=5,\n",
    "              optimizer='adam',\n",
    "              optimizer_params={'lr':1e-3},\n",
    "              loss='bce',\n",
    "              regularizer='LP', \n",
    "              regularizer_params={'p':3, 'lambda':1e-5},\n",
    "              verbose=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name = 'RandomBaseline'\n",
    "model = RandomBaseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'DistMult'\n",
    "model = DistMult(batches_count=100,\n",
    "                 seed=555,\n",
    "                 epochs=EPOCHS,\n",
    "                 k=150,\n",
    "                 eta=5,\n",
    "                 loss='pairwise',\n",
    "                 loss_params={'margin':5})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name = 'ComplEx'\n",
    "model = ComplEx(batches_count=100,\n",
    "                seed=555,\n",
    "                epochs=EPOCHS,\n",
    "                k=150,\n",
    "                eta=5,\n",
    "                loss='pairwise',\n",
    "                loss_params={'margin':1},\n",
    "                regularizer='LP',\n",
    "                regularizer_params={'p': 2, 'lambda':0.1})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name = 'TransE'\n",
    "model = TransE(batches_count=100,\n",
    "               seed=555,\n",
    "               epochs=EPOCHS,\n",
    "               k=100,\n",
    "               eta=5,\n",
    "               loss='pairwise',\n",
    "               loss_params={'margin':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING - DeprecationWarning: use_default_protocol will be removed in future. Please use corrupt_side argument instead.\n"
     ]
    }
   ],
   "source": [
    "ranks = evaluate_performance(X_test, \n",
    "                             model=model, \n",
    "                             filter_triples=positives_filter,\n",
    "                             filter_unseen=True,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performances = {}\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "model_performances['mrr'] = mrr\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "model_performances['hits_10'] = hits_10\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "model_performances['hits_3'] = hits_3\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "model_performances['hits_1'] = hits_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performances = {key:[value] for key,value in model_performances.items()}\n",
    "df_model_performances = pd.DataFrame.from_dict(model_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrr</th>\n",
       "      <th>hits_10</th>\n",
       "      <th>hits_3</th>\n",
       "      <th>hits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188698</td>\n",
       "      <td>0.260647</td>\n",
       "      <td>0.206985</td>\n",
       "      <td>0.143952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mrr   hits_10    hits_3    hits_1\n",
       "0  0.188698  0.260647  0.206985  0.143952"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_performances"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "df_model_performances.to_csv('results/model_performances'+model_name+'.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 : Determining the distance threshold for matching \n",
    "\n",
    "- In this part, we sample a set of pairs and for each of them compute its (i) distance and (ii) similarity measure\n",
    "- Then, we model the relation between the 2 measures and obtain a distance threshold based on the given parameter on the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_target_class_instances = [x[0] for x in X if x[1]==PATH_TYPE and x[2]==TYPE_TARGET_CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = list(np.unique([x[2] for x in X if x[1] == PATH_TYPE]))\n",
    "type_end = all_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters_DBPedia import dic_functionality\n",
    "dic_functionality = {key:value for key,value in dic_functionality.items() if key not in [PATH_OUTCOME[0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'http://dbpedia.org/ontology/arwuW': 1,\n",
       " 'http://dbpedia.org/ontology/author': 1,\n",
       " 'http://dbpedia.org/ontology/birthDate': 1,\n",
       " 'http://dbpedia.org/ontology/countryName': 1,\n",
       " 'http://dbpedia.org/ontology/endowment': 1,\n",
       " 'http://dbpedia.org/ontology/genre': 1,\n",
       " 'http://dbpedia.org/ontology/hasForStudent': 1,\n",
       " 'http://dbpedia.org/ontology/isCountryOf': 1,\n",
       " 'http://dbpedia.org/ontology/numberOfPages': 1,\n",
       " 'http://xmlns.com/foaf/0.1/gender': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 : Compute similarity for two instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects_of_property(property_,X):\n",
    "    \"\"\"\n",
    "    Returns possible objects for a property.\n",
    "    \"\"\"\n",
    "    return list(np.unique([x[0] for x in X if x[1] == property_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_array_triples_for_subject(object_,property_,subjects_):\n",
    "    \"\"\"\n",
    "    Generates all possible triples in the appropriate format to assess their score afterwards.\n",
    "    \"\"\"\n",
    "    return np.array([[s,property_,object_] for s in subjects_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_values_scores_for_subject(subjects_,property_,object_,scores_):\n",
    "    df_ = pd.DataFrame()\n",
    "    for i in range(len(subjects_)):\n",
    "        dic_add = {\n",
    "            'subject':subjects_[i],\n",
    "            'predicate':property_,\n",
    "            'object':object_,\n",
    "            'score':scores_[i]\n",
    "        }\n",
    "        df_ = df_.append(dic_add,ignore_index=True)\n",
    "    df_ = df_.sort_values(by=['score'],ascending=False)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_subjects_for_property_object(property_,object_,subjects_,model,func_):\n",
    "    \"\"\"\n",
    "    Obtain the list of the top ranked subjects for a property p_ and an object given the model.\n",
    "    \"\"\"\n",
    "    triples_ent_ = generate_array_triples_for_subject(object_,property_,subjects_)\n",
    "    scores_ = model.predict(triples_ent_)\n",
    "    df_ = create_df_values_scores_for_subject(subjects_,property_,object_,scores_)\n",
    "    return list(df_['subject'])[:func_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_endowment(endowment_text):\n",
    "    if 'E' in endowment_text:\n",
    "        return float(endowment_text.split('E')[0])*10**(int(endowment_text.split('E')[1]))\n",
    "    else:\n",
    "        return float(endowment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DBPedia_similarity(pair_,model,X,dic_functionality):\n",
    "    similarity = []\n",
    "    entity_0 = pair_[0]\n",
    "    entity_1 = pair_[1]\n",
    "    \n",
    "    try:\n",
    "        # birthdate\n",
    "        p_ = 'http://dbpedia.org/ontology/birthDate'\n",
    "        objects_for_p = get_objects_of_property(p_,X)\n",
    "        birthdate_i0 = int(get_n_objects_for_property_entity(entity_0,p_,objects_for_p,model,dic_functionality[p_])[0])\n",
    "        birthdate_i1 = int(get_n_objects_for_property_entity(entity_1,p_,objects_for_p,model,dic_functionality[p_])[0])\n",
    "        if abs(birthdate_i0-birthdate_i1) <= 15:\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)\n",
    "\n",
    "        # genre\n",
    "        p_ = 'http://dbpedia.org/ontology/genre'\n",
    "        objects_for_p = get_objects_of_property(p_,X)\n",
    "        genre_i0 = get_n_objects_for_property_entity(entity_0,p_,objects_for_p,model,dic_functionality[p_])[0]\n",
    "        genre_i1 = get_n_objects_for_property_entity(entity_1,p_,objects_for_p,model,dic_functionality[p_])[0]\n",
    "        if genre_i0 == genre_i1:\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)\n",
    "\n",
    "        # gender\n",
    "        p_ = 'http://xmlns.com/foaf/0.1/gender'\n",
    "        objects_for_p = get_objects_of_property(p_,X)\n",
    "        gender_i0 = get_n_objects_for_property_entity(entity_0,p_,objects_for_p,model,dic_functionality[p_])[0]\n",
    "        gender_i1 = get_n_objects_for_property_entity(entity_1,p_,objects_for_p,model,dic_functionality[p_])[0]\n",
    "        if gender_i0 == gender_i1:\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            similarity.append(0)\n",
    "\n",
    "        # university\n",
    "        p_ = 'http://dbpedia.org/ontology/hasForStudent'\n",
    "        subjects_for_p = get_subjects_of_property(p_,X)\n",
    "        uni_i0 = get_n_subjects_for_property_object(p_,entity_0,subjects_for_p,model,dic_functionality[p_])[0]\n",
    "        uni_i1 = get_n_subjects_for_property_object(p_,entity_1,subjects_for_p,model,dic_functionality[p_])[0]\n",
    "        if uni_i0 == uni_i1:\n",
    "            similarity.append(1)\n",
    "        else:\n",
    "            # if different\n",
    "            # arwuW\n",
    "            p_ = 'http://dbpedia.org/ontology/arwuW'\n",
    "            objects_for_p = get_objects_of_property(p_,X)\n",
    "            arwu_i0 = int(get_n_objects_for_property_entity(uni_i0,p_,objects_for_p,model,dic_functionality[p_])[0])\n",
    "            arwu_i1 = int(get_n_objects_for_property_entity(uni_i1,p_,objects_for_p,model,dic_functionality[p_])[0])\n",
    "\n",
    "            if abs(arwu_i0-arwu_i1) <= 30:\n",
    "                similarity.append(1)\n",
    "            else:\n",
    "                similarity.append(0)\n",
    "\n",
    "            # endowment\n",
    "            p_ = 'http://dbpedia.org/ontology/endowment'\n",
    "            objects_for_p = get_objects_of_property(p_,X)\n",
    "            endowment_i0 = get_endowment(get_n_objects_for_property_entity(uni_i0,p_,objects_for_p,model,dic_functionality[p_])[0])\n",
    "            endowment_i1 = get_endowment(get_n_objects_for_property_entity(uni_i1,p_,objects_for_p,model,dic_functionality[p_])[0])\n",
    "            min_ = min([endowment_i0,endowment_i1])\n",
    "            max_ = max([endowment_i0,endowment_i1])\n",
    "            if max_/min_ < 2:\n",
    "                similarity.append(1)\n",
    "            else:\n",
    "                similarity.append(0)\n",
    "\n",
    "            # country\n",
    "            p_ = 'http://dbpedia.org/ontology/isCountryOf'\n",
    "            subjects_for_p = get_subjects_of_property(p_,X)\n",
    "            country_i0 = get_n_subjects_for_property_object(p_,uni_i0,subjects_for_p,model,dic_functionality[p_])[0]\n",
    "            country_i0 = get_n_subjects_for_property_object(p_,uni_i1,subjects_for_p,model,dic_functionality[p_])[0]\n",
    "            if gender_i0 == gender_i1:\n",
    "                similarity.append(1)\n",
    "            else:\n",
    "                similarity.append(0)\n",
    "\n",
    "        return sum(similarity)/len(similarity)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pairs = list(itertools.combinations(list_target_class_instances,2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_distance, list_similarity = [], []\n",
    "number_pairs = 500\n",
    "pairs_compute = random.sample(list_pairs,number_pairs)\n",
    "for pair_ in pairs_compute:\n",
    "    list_distance.append(get_distance_for_pair(pair_,model))\n",
    "    list_similarity.append(get_DBPedia_similarity(pair_,model,X,dic_functionality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distributed_points(list_distance,list_similarity,number_intervals,number_per_interval):\n",
    "    distance_ = max(list_distance) - min(list_distance)\n",
    "    interval_length = distance_/(number_intervals-1)\n",
    "    dic_points = {(min(list_distance)+interval_length*i,min(list_distance)+interval_length*(i+1)):[] for i in range(number_intervals-1)}\n",
    "    \n",
    "    # adding points\n",
    "    for i in range(len(list_distance)):\n",
    "        for interval, list_points in dic_points.items():\n",
    "            distance_point = list_distance[i]\n",
    "            if distance_point >= interval[0] and distance_point <= interval[1]:\n",
    "                dic_points[interval] = dic_points[interval] + [i] \n",
    "                \n",
    "    # subsampling\n",
    "    dic_points_sampled = {}\n",
    "    for interval, list_points in dic_points.items():\n",
    "        if len(list_points) <= number_per_interval:\n",
    "            dic_points_sampled[interval] = list_points\n",
    "        else:\n",
    "            dic_points_sampled[interval] = random.sample(list_points,number_per_interval)\n",
    "                \n",
    "    # getting points\n",
    "    update_distance,update_similarity = [], []\n",
    "    for interval, list_index in dic_points_sampled.items():\n",
    "        for i in list_index:\n",
    "            update_distance.append(list_distance[i])\n",
    "            update_similarity.append(list_similarity[i])\n",
    "    \n",
    "    return update_distance,update_similarity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "update_distance,update_similarity = get_distributed_points(list_distance,list_similarity,number_intervals=10,number_per_interval=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# adding extra points with short distance\n",
    "for pair_ in pairs_closer_instances:\n",
    "    update_distance.append(get_distance_for_pair(pair_,model))\n",
    "    update_similarity.append(get_DBPedia_similarity(pair_,model,X,dic_functionality))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.scatter(update_distance,update_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treatment_DBPedia(instance,X,treatment_path):\n",
    "    if treatment_path == 'http://dbpedia.org/ontology/birthDate':\n",
    "        return int([(x[2]) for x in X if x[0] == instance and x[1] == treatment_path][0])\n",
    "    elif treatment_path == 'http://xmlns.com/foaf/0.1/gender':\n",
    "        return [(x[2]) for x in X if x[0] == instance and x[1] == treatment_path][0]\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/genre':\n",
    "        return [(x[2]) for x in X if x[0] == instance and x[1] == treatment_path][0]\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/arwuW':\n",
    "        uni = [x[0] for x in X if x[2] == instance and x[1] == 'http://dbpedia.org/ontology/hasForStudent']\n",
    "        rank_uni = [x[2] for x in X if x[0] == uni[0] and x[1] == 'http://dbpedia.org/ontology/arwuW']\n",
    "        return int(rank_uni[0])\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/countryName':\n",
    "        uni = [x[0] for x in X if x[2] == instance and x[1] == 'http://dbpedia.org/ontology/hasForStudent']\n",
    "        country_uni = [x[0] for x in X if x[2] == uni[0] and x[1] == 'http://dbpedia.org/ontology/isCountryOf']\n",
    "        return country_uni[0]\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/endowment':\n",
    "        uni = [x[0] for x in X if x[2] == instance and x[1] == 'http://dbpedia.org/ontology/hasForStudent']\n",
    "        endowment_uni = [x[2] for x in X if x[0] == uni[0] and x[1] == 'http://dbpedia.org/ontology/endowment']\n",
    "        try:\n",
    "            return get_endowment(endowment_uni[0])\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 : Relation between distance and similarity metric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_pairs = draw_set_of_pairs(list_target_class_instances)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_pairs[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_distance_for_pair(sample_pairs[0],model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "measures = get_measures_for_pairs(sample_pairs[:SAMPLING_PARAMETER],model,X,dic_functionality,type_end,PATH_TYPE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subset_points = get_subset_points_for_threshold(measures)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(subset_points))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_name = 'ConvE'\n",
    "plot_distribution_measures(subset_points,model_name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_degree = 1\n",
    "estimation_model, r_squared = fit_model_on_measures(subset_points,model_degree)\n",
    "print(f\"The r² score of the model is {round(r_squared,4)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fitted_model = estimation_model\n",
    "plot_distribution_and_model(measures,fitted_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "distance_threshold = get_distance_threshold(fitted_model,SIMILARITY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "distance_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 : Building the pairs of similar instances\n",
    "\n",
    "- We mined the distance threshold, we can now create the pairs\n",
    "- Showing the different strategies to obtain the pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 185 instances of the target class.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(list_target_class_instances)} instances of the target class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 : Building the pairs of similar instances : No condition on the treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the similarity matrix\n",
    "mode = 'mixed'\n",
    "df_similarity,df_to_numpy = get_matrix_similarity_pairs(model,list_target_class_instances,mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 185)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similarity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 : Using the distance threshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "strategy = 'greedy'\n",
    "pairs_similar_instances = get_pairs_from_matrix_and_threshold(df_similarity,distance_threshold,strategy=strategy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(f\"{len(pairs_similar_instances)} pairs have been created with the greedy strategy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 : Using the proportion of matched instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 pairs have been created.\n"
     ]
    }
   ],
   "source": [
    "proportion = 0.015\n",
    "pairs_closer_instances = get_pairs_from_matrix_and_proportion(df_similarity,proportion=proportion)\n",
    "print(f\"{len(pairs_closer_instances)} pairs have been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 : Building the pairs of similar instances : Different treatment values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mode = 'treatment_sort'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "treatment_values = list(np.unique([x[2] for x in X if x[1]==PATH_TREATMENT[0]]))\n",
    "t0 = treatment_values[0]\n",
    "t1 = treatment_values[1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "instances_t0 = list(np.unique([x[0] for x in X if x[2]==t0]))\n",
    "instances_t1 = list(np.unique([x[0] for x in X if x[2]==t1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_similarity,df_to_numpy = get_matrix_similarity_pairs(model,list_target_class_instances,mode=mode,instances_t0=instances_t0,instances_t1=instances_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 : Using the distance threshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "distance_thr = distance_threshold + 0.2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "strategy = 'greedy'\n",
    "pairs_similar_instances = get_pairs_from_matrix_and_threshold(df_similarity,distance_thr,strategy=strategy,mode=mode)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(pairs_similar_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 : Using the proportion of matched instances"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "proportion = 0.001\n",
    "mode = 'treatment_sort'\n",
    "pairs_closer_instances = get_pairs_from_matrix_and_proportion(df_similarity,proportion=proportion,mode=mode)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(f\"{len(pairs_closer_instances)} pairs have been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 : Computing the treatment effect\n",
    "\n",
    "- Given the set of similar pairs, we aim to compute the treatment effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 : Getting treatment and outcome values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome_DBPedia(instance,X):\n",
    "    date_birth = [(x[2]) for x in X if x[0] == instance and x[1] == 'http://dbpedia.org/ontology/birthDate'][0]\n",
    "    books_published = [(x[2]) for x in X if x[0] == instance and x[1] == 'http://dbpedia.org/ontology/author']\n",
    "    dates_published = [x[2] for book in books_published for x in X if x[0] == book and x[1]=='http://dbpedia.org/ontology/releaseDate']\n",
    "    return min([int(date) for date in dates_published]) - int(date_birth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_endowment(endowment_text):\n",
    "    if 'E' in endowment_text:\n",
    "        return float(endowment_text.split('E')[0])*10**(int(endowment_text.split('E')[1]))\n",
    "    else:\n",
    "        return float(endowment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treatment_DBPedia(instance,X,treatment_path):\n",
    "    if treatment_path == 'http://dbpedia.org/ontology/birthDate':\n",
    "        return int([(x[2]) for x in X if x[0] == instance and x[1] == treatment_path][0])\n",
    "    elif treatment_path == 'http://xmlns.com/foaf/0.1/gender':\n",
    "        return [(x[2]) for x in X if x[0] == instance and x[1] == treatment_path][0]\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/genre':\n",
    "        return [(x[2]) for x in X if x[0] == instance and x[1] == treatment_path][0]\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/arwuW':\n",
    "        uni = [x[0] for x in X if x[2] == instance and x[1] == 'http://dbpedia.org/ontology/hasForStudent']\n",
    "        rank_uni = [x[2] for x in X if x[0] == uni[0] and x[1] == 'http://dbpedia.org/ontology/arwuW']\n",
    "        return int(rank_uni[0])\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/countryName':\n",
    "        uni = [x[0] for x in X if x[2] == instance and x[1] == 'http://dbpedia.org/ontology/hasForStudent']\n",
    "        country_uni = [x[0] for x in X if x[2] == uni[0] and x[1] == 'http://dbpedia.org/ontology/isCountryOf']\n",
    "        return country_uni[0]\n",
    "    elif treatment_path == 'http://dbpedia.org/ontology/endowment':\n",
    "        uni = [x[0] for x in X if x[2] == instance and x[1] == 'http://dbpedia.org/ontology/hasForStudent']\n",
    "        endowment_uni = [x[2] for x in X if x[0] == uni[0] and x[1] == 'http://dbpedia.org/ontology/endowment']\n",
    "        try:\n",
    "            return get_endowment(endowment_uni[0])\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_treatment_path = {\n",
    "    'birthDate':'http://dbpedia.org/ontology/birthDate',\n",
    "    'gender':'http://xmlns.com/foaf/0.1/gender',\n",
    "    'genre':'http://dbpedia.org/ontology/genre',\n",
    "    'arwuW':'http://dbpedia.org/ontology/arwuW',\n",
    "    'countryName':'http://dbpedia.org/ontology/countryName',\n",
    "    'endowment':'http://dbpedia.org/ontology/endowment'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 : Defining metrics : numerical and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_metric(set_pairs,X,treatment_path):\n",
    "    m_m,m_e,m_l = 0,0,0\n",
    "    e_d,e_e = 0,0\n",
    "    \n",
    "    for pair in set_pairs:\n",
    "        value_t0 = get_treatment_DBPedia(pair[0],X,treatment_path)\n",
    "        value_t1 = get_treatment_DBPedia(pair[1],X,treatment_path)\n",
    "        \n",
    "        if value_t0 > 0 and value_t1 > 0:\n",
    "            value_o0 = get_outcome_DBPedia(pair[0],X)\n",
    "            value_o1 = get_outcome_DBPedia(pair[1],X)\n",
    "\n",
    "            if value_t0 > value_t1:\n",
    "                if value_o0 > value_o1:\n",
    "                    m_m += 1\n",
    "                elif value_o0 == value_o1:\n",
    "                    m_e += 1\n",
    "                else:\n",
    "                    m_l += 1\n",
    "\n",
    "            elif value_t0 == value_t1:\n",
    "                if value_o0 > value_o1 or value_o0 < value_o1:\n",
    "                    e_d += 1\n",
    "                else:\n",
    "                    e_e += 1\n",
    "\n",
    "            else:\n",
    "                if value_o0 > value_o1:\n",
    "                    m_l += 1\n",
    "                elif value_o0 == value_o1:\n",
    "                    m_e += 1\n",
    "                else:\n",
    "                    m_m += 1\n",
    "    \n",
    "    if m_l > 0:\n",
    "        return m_m,m_e,m_l,e_d+e_e,m_m/m_l\n",
    "    else:\n",
    "        return m_m,m_e,m_l,e_d+e_e,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_metric(set_pairs,X,treatment_path,t0,t1):\n",
    "    T_m,T_e,T_l = 0,0,0\n",
    "    notT_d,notT_e = 0,0\n",
    "    \n",
    "    for pair in set_pairs:\n",
    "        value_t0 = get_treatment_DBPedia(pair[0],X,treatment_path)\n",
    "        value_t1 = get_treatment_DBPedia(pair[1],X,treatment_path)\n",
    "        \n",
    "        value_o0 = get_outcome_DBPedia(pair[0],X)\n",
    "        value_o1 = get_outcome_DBPedia(pair[1],X)\n",
    "        \n",
    "        if value_t0 == t0 and value_t1 == t1:\n",
    "            if value_o0 > value_o1:\n",
    "                T_m += 1\n",
    "            elif value_o0 == value_o1:\n",
    "                T_e += 1\n",
    "            else:\n",
    "                T_l += 1\n",
    "                \n",
    "                \n",
    "        elif value_t0 == t1 and value_t1 == t0:\n",
    "            if value_o0 > value_o1:\n",
    "                T_l += 1\n",
    "            elif value_o0 == value_o1:\n",
    "                T_e += 1\n",
    "            else:\n",
    "                T_m += 1\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            if value_o0 > value_o1 or value_o0 < value_o1:\n",
    "                notT_d += 1\n",
    "            else:\n",
    "                notT_e += 1\n",
    "    \n",
    "    if T_l > 0:\n",
    "        return T_m,T_e,T_l,notT_d+notT_e,T_m/T_l\n",
    "    else:\n",
    "        return T_m,T_e,T_l,notT_d+notT_e,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 : Getting treatment effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['treatment','#_pairs','type','treatment_values','metric','#_rule','#_not_rule','#_same']\n",
    "df_saving_rules = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 pairs have been created.\n"
     ]
    }
   ],
   "source": [
    "proportion = 0.02\n",
    "pairs_closer_instances = get_pairs_from_matrix_and_proportion(df_similarity,proportion=proportion)\n",
    "print(f\"{len(pairs_closer_instances)} pairs have been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 : Birth Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_path = 'http://dbpedia.org/ontology/birthDate'\n",
    "m_m,m_e,m_l,e_,metric = get_numerical_metric(pairs_closer_instances,X,treatment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'gradual'\n",
    "dic_rule['treatment_values'] = 'higher_implies_higher'\n",
    "dic_rule['metric'] = metric\n",
    "dic_rule['#_rule'] = m_m\n",
    "dic_rule['#_not_rule'] = m_l\n",
    "dic_rule['#_same'] = m_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 : Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_path = 'http://xmlns.com/foaf/0.1/gender'\n",
    "t0 = 'male'\n",
    "t1 = 'female'\n",
    "T_m,T_e,T_l,not_T,metric = get_categorical_metric(pairs_closer_instances,X,treatment_path,t0,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'categorical'\n",
    "dic_rule['treatment_values'] = t0 + ' vs ' + t1\n",
    "dic_rule['metric'] = metric\n",
    "dic_rule['#_rule'] = T_m\n",
    "dic_rule['#_not_rule'] = T_l\n",
    "dic_rule['#_same'] = T_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3 : Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_path = 'http://dbpedia.org/ontology/genre'\n",
    "t0 = 'Fiction'\n",
    "t1 = 'NonFiction'\n",
    "T_m,T_e,T_l,not_T,metric = get_categorical_metric(pairs_closer_instances,X,treatment_path,t0,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'categorical'\n",
    "dic_rule['treatment_values'] = t0 + ' vs ' + t1\n",
    "dic_rule['metric'] = metric\n",
    "dic_rule['#_rule'] = T_m\n",
    "dic_rule['#_not_rule'] = T_l\n",
    "dic_rule['#_same'] = T_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4 : arwuW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_path = 'http://dbpedia.org/ontology/arwuW'\n",
    "m_m,m_e,m_l,e_,metric = get_numerical_metric(pairs_closer_instances,X,treatment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'gradual'\n",
    "dic_rule['treatment_values'] = 'higher_implies_higher'\n",
    "dic_rule['metric'] = metric\n",
    "dic_rule['#_rule'] = m_m\n",
    "dic_rule['#_not_rule'] = m_l\n",
    "dic_rule['#_same'] = m_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.5 : countryName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asia', 'Canada', 'England', 'Nan', 'U.S.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.unique([x[2] for x in X if x[1]=='http://dbpedia.org/ontology/countryName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_path = 'http://dbpedia.org/ontology/countryName'\n",
    "t0 = 'England'\n",
    "t1 = 'U.S.'\n",
    "T_m,T_e,T_l,not_T,metric = get_categorical_metric(pairs_closer_instances,X,treatment_path,t0,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'categorical'\n",
    "dic_rule['treatment_values'] = t0 + ' vs ' + t1\n",
    "dic_rule['metric'] = metric\n",
    "dic_rule['#_rule'] = T_m\n",
    "dic_rule['#_not_rule'] = T_l\n",
    "dic_rule['#_same'] = T_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = 'U.S.'\n",
    "t1 = 'Canada'\n",
    "T_m,T_e,T_l,not_T,metric = get_categorical_metric(pairs_closer_instances,X,treatment_path,t0,t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'categorical'\n",
    "dic_rule['treatment_values'] = t0 + ' vs ' + t1\n",
    "dic_rule['metric'] = metric\n",
    "dic_rule['#_rule'] = T_m\n",
    "dic_rule['#_not_rule'] = T_l\n",
    "dic_rule['#_same'] = T_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.6 : endowment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_path = 'http://dbpedia.org/ontology/endowment'\n",
    "m_m,m_e,m_l,e_,metric = get_numerical_metric(pairs_closer_instances,X,treatment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = treatment_path.split('/')[-1]\n",
    "dic_rule['#_pairs'] = len(pairs_closer_instances)\n",
    "dic_rule['type'] = 'gradual'\n",
    "dic_rule['treatment_values'] = 'higher_implies_higher'\n",
    "dic_rule['metric'] = metric \n",
    "dic_rule['#_rule'] = m_m\n",
    "dic_rule['#_not_rule'] = m_l\n",
    "dic_rule['#_same'] = m_e\n",
    "\n",
    "df_saving_rules = df_saving_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saving_rules"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_saving_rules.to_csv('rules_DBPedia_embeddings.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 : Adding confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_interval(value_rule,value_not_rule,stat_param=1.96):\n",
    "    if value_rule > 0 and value_not_rule > 0:\n",
    "        metric = value_rule/value_not_rule\n",
    "        log_m = math.log(metric)\n",
    "        interval_amp = stat_param*math.sqrt((1/value_rule)+(1/value_not_rule))\n",
    "        return round(metric,3), [round(math.exp(log_m - interval_amp),3),round(math.exp(log_m + interval_amp),3)]\n",
    "    else:\n",
    "        return None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_metric_low_value = []\n",
    "list_metric_high_value = []\n",
    "stat_param = 1.28\n",
    "\n",
    "for index, row in df_saving_rules.iterrows():\n",
    "    metric_,metric_IC = compute_interval(row['#_rule'],row['#_not_rule'],stat_param=stat_param)\n",
    "    if metric_:\n",
    "        list_metric_low_value.append(metric_IC[0])\n",
    "        list_metric_high_value.append(metric_IC[1])\n",
    "    else:\n",
    "        list_metric_low_value.append(1)\n",
    "        list_metric_high_value.append(1)\n",
    "        \n",
    "df_saving_rules['metric_IC_low'] = list_metric_low_value\n",
    "df_saving_rules['metric_IC_high'] = list_metric_high_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saving_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_treatment_higher = df_saving_rules[df_saving_rules['metric_IC_low']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = []\n",
    "for treatment in list(np.unique(rules_treatment_higher['treatment'])):\n",
    "    df_ = rules_treatment_higher[rules_treatment_higher['treatment']==treatment]\n",
    "    df_ = df_.sort_values([\"#_pairs\"],ascending=True)\n",
    "    df_select.append(df_[0:1][:])\n",
    "    \n",
    "df_rule_higher = pd.concat(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_treatment_lower = df_saving_rules[df_saving_rules['metric_IC_high']<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = []\n",
    "for treatment in list(np.unique(rules_treatment_lower['treatment'])):\n",
    "    df_ = rules_treatment_lower[rules_treatment_lower['treatment']==treatment]\n",
    "    df_ = df_.sort_values([\"#_pairs\"],ascending=True)\n",
    "    df_select.append(df_[0:1][:])\n",
    "    \n",
    "df_rule_lower = pd.concat(df_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rule_higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rule_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 : Number of Pairs Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_explained(pair,df_rule_high,df_rule_low,dic_treatment_path):\n",
    "    outcome_i0 = get_outcome_DBPedia(pair[0],X)\n",
    "    outcome_i1 = get_outcome_DBPedia(pair[1],X)\n",
    "    \n",
    "    for item, row in df_rule_high.iterrows():\n",
    "        treatment_path = dic_treatment_path[row['treatment']]\n",
    "        value_t0 = get_treatment_DBPedia(pair[0],X,treatment_path)\n",
    "        value_t1 = get_treatment_DBPedia(pair[1],X,treatment_path)\n",
    "        \n",
    "        if row['type'] == 'gradual':\n",
    "            if outcome_i0 > outcome_i1 and value_t0 > value_t1:\n",
    "                return 1\n",
    "            elif outcome_i0 < outcome_i1 and value_t0 < value_t1:\n",
    "                return 1\n",
    "    \n",
    "    for item, row in df_rule_low.iterrows():\n",
    "        treatment_path = dic_treatment_path[row['treatment']]\n",
    "        value_t0 = get_treatment_DBPedia(pair[0],X,treatment_path)\n",
    "        value_t1 = get_treatment_DBPedia(pair[1],X,treatment_path)\n",
    "        \n",
    "        if row['type'] == 'gradual':\n",
    "            if outcome_i0 > outcome_i1 and value_t0 < value_t1:\n",
    "                return 1\n",
    "            elif outcome_i0 < outcome_i1 and value_t0 > value_t1:\n",
    "                return 1\n",
    "            \n",
    "        else:\n",
    "            t0_rule = row['treatment_values'].split(' vs ')[0]\n",
    "            t1_rule = row['treatment_values'].split(' vs ')[1]\n",
    "            \n",
    "            if value_t0 == t0_rule and value_t1 == t1_rule and outcome_i0 < outcome_i1:\n",
    "                return 1\n",
    "            elif value_t0 == t1_rule and value_t1 == t0_rule and outcome_i0 > outcome_i1:\n",
    "                return 1\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pairs = list(itertools.combinations(list_target_class_instances,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_parameter = 1000\n",
    "sample_pairs = random.sample(list_pairs,sampling_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained = 0\n",
    "for pair in sample_pairs:\n",
    "    explained += get_if_explained(pair,df_rule_higher,df_rule_lower,dic_treatment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of pairs explained : \",round(explained*100/len(sample_pairs),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :\n",
    "- si trop peu d'instances : on aura que très peu de règles car IC large\n",
    "- si trop d'instances : il y aura des règles mais avec des paires peu similaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 : Comparison to K-CAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_treatment_path = {\n",
    "    'birthDate':'http://dbpedia.org/ontology/birthDate',\n",
    "    'gender':'http://xmlns.com/foaf/0.1/gender',\n",
    "    'genre':'http://dbpedia.org/ontology/genre',\n",
    "    'arwuW':'http://dbpedia.org/ontology/arwuW',\n",
    "    'countryName':'http://dbpedia.org/ontology/countryName',\n",
    "    'endowment':'http://dbpedia.org/ontology/endowment'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 : Defining the set of K-CAP rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['treatment','treatment_type','t0_value','t1_value','strata']\n",
    "df_KCAP_rules = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'arwuW'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_older'\n",
    "dic_rule['t1_value'] = 'lower_publish_younger'\n",
    "dic_rule['strata'] = {\n",
    "    'genre':['Fiction'],\n",
    "    'gender':['male'],\n",
    "    'birthDate':(1800,1934),\n",
    "    'countryName':['England','U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'arwuW'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_older'\n",
    "dic_rule['t1_value'] = 'lower_publish_younger'\n",
    "dic_rule['strata'] = {\n",
    "    'genre':['Fiction'],\n",
    "    'gender':['male'],\n",
    "    'birthDate':(1800,2000),\n",
    "    'countryName':['U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'arwuW'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_older'\n",
    "dic_rule['t1_value'] = 'lower_publish_younger'\n",
    "dic_rule['strata'] = {\n",
    "    'genre':['Fiction'],\n",
    "    'birthDate':(1935,1959),\n",
    "    'countryName':['U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'arwuW'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_younger'\n",
    "dic_rule['t1_value'] = 'lower_publish_older'\n",
    "dic_rule['strata'] = {\n",
    "    'genre':['NonFiction'],\n",
    "    'gender':['male'],\n",
    "    'birthDate':(1935,1959),\n",
    "    'countryName':['U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "birthDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'birthDate'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_older'\n",
    "dic_rule['t1_value'] = 'lower_publish_younger'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(1,100),\n",
    "    'genre':['Fiction'],\n",
    "    'gender':['male'],\n",
    "    'countryName':['England']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'birthDate'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_younger'\n",
    "dic_rule['t1_value'] = 'lower_publish_older'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(1,100),\n",
    "    'genre':['Fiction'],\n",
    "    'countryName':['U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'birthDate'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_younger'\n",
    "dic_rule['t1_value'] = 'lower_publish_older'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(1,100),\n",
    "    'gender':['male'],\n",
    "    'countryName':['U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'birthDate'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_younger'\n",
    "dic_rule['t1_value'] = 'lower_publish_older'\n",
    "dic_rule['strata'] = {\n",
    "    'genre':['Fiction'],\n",
    "    'countryName':['U.S.']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'birthDate'\n",
    "dic_rule['treatment_type'] = 'gradual'\n",
    "dic_rule['t0_value'] = 'higher_publish_younger'\n",
    "dic_rule['t1_value'] = 'lower_publish_older'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(101,600),\n",
    "    'genre':['Fiction'],\n",
    "    'gender':['male'],\n",
    "    'countryName':['U.S.','Canada','England']\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'genre'\n",
    "dic_rule['treatment_type'] = 'categorial'\n",
    "dic_rule['t0_value'] = 'Fiction'\n",
    "dic_rule['t1_value'] = 'NonFiction'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(1,100),\n",
    "    'gender':['male'],\n",
    "    'countryName':['U.S.'],\n",
    "    'birthDate':[(1800,1934),(1960,2000)]\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'gender'\n",
    "dic_rule['treatment_type'] = 'categorial'\n",
    "dic_rule['t0_value'] = 'male'\n",
    "dic_rule['t1_value'] = 'female'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(1,100),\n",
    "    'genre':['Fiction'],\n",
    "    'countryName':['U.S.'],\n",
    "    'birthDate':(1800,2000)\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'gender'\n",
    "dic_rule['treatment_type'] = 'categorial'\n",
    "dic_rule['t0_value'] = 'male'\n",
    "dic_rule['t1_value'] = 'female'\n",
    "dic_rule['strata'] = {\n",
    "    'genre':['Fiction'],\n",
    "    'countryName':['U.S.'],\n",
    "    'birthDate':(1935, 1959)\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_rule = {}\n",
    "dic_rule['treatment'] = 'gender'\n",
    "dic_rule['treatment_type'] = 'categorial'\n",
    "dic_rule['t0_value'] = 'female'\n",
    "dic_rule['t1_value'] = 'male'\n",
    "dic_rule['strata'] = {\n",
    "    'arwuW':(101,600),\n",
    "    'genre':['Fiction'],\n",
    "    'countryName':['U.S.'],\n",
    "    'birthDate':[(1800,1934),(1960,2000)]\n",
    "}\n",
    "df_KCAP_rules = df_KCAP_rules.append(dic_rule,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_KCAP_rules.to_csv('KCAP_Rules.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_treatment_outcome_pair_in_rule(row_df,pair_,X,dic_treatment_path):\n",
    "    outcome_0 = get_outcome_DBPedia(pair_[0],X)\n",
    "    outcome_1 = get_outcome_DBPedia(pair_[1],X)\n",
    "    \n",
    "    treatment_name = row_df['treatment']\n",
    "    treatment_value_0 = get_treatment_DBPedia(pair_[0],X,dic_treatment_path[treatment_name])\n",
    "    treatment_value_1 = get_treatment_DBPedia(pair_[1],X,dic_treatment_path[treatment_name])\n",
    "    \n",
    "    if row_df['treatment_type'] == 'categorical':\n",
    "        if treatment_value_0 == row_df['t0_value'] and treatment_value_1 == row_df['t1_value']:\n",
    "            if outcome_0 < outcome_1:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif treatment_value_0 == row_df['t1_value'] and treatment_value_1 == row_df['t0_value']:\n",
    "            if outcome_1 < outcome_0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    else:\n",
    "        if row_df['t0_value'] == 'higher_publish_older':\n",
    "            if treatment_value_0 > treatment_value_1 and outcome_0 > outcome_1:\n",
    "                return True\n",
    "            elif treatment_value_0 < treatment_value_1 and outcome_0 < outcome_1:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            if treatment_value_0 > treatment_value_1 and outcome_0 < outcome_1:\n",
    "                return True\n",
    "            elif treatment_value_0 < treatment_value_1 and outcome_0 > outcome_1:\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_pair_in_strata(row_df,pair_,X,dic_treatment_path):\n",
    "    for prop_name,strata_value in row_df['strata'].items():\n",
    "        \n",
    "        value_0 = get_treatment_DBPedia(pair_[0],X,dic_treatment_path[prop_name])\n",
    "        value_1 = get_treatment_DBPedia(pair_[1],X,dic_treatment_path[prop_name])\n",
    "        \n",
    "        if prop_name == 'countryName':\n",
    "            value_0 = value_0.split('/')[-1]\n",
    "            value_1 = value_1.split('/')[-1]\n",
    "        \n",
    "        if prop_name not in ['birthDate','arwuW']:\n",
    "            if value_0 not in strata_value or value_1 not in strata_value:\n",
    "                return False\n",
    "        elif prop_name == 'arwuW':\n",
    "            if value_0 < strata_value[0] or value_0 > strata_value[1] or value_1 < strata_value[0] or value_1 > strata_value[1]:\n",
    "                return False\n",
    "        elif prop_name == 'birthDate':\n",
    "            if type(strata_value)!=list:\n",
    "                if value_0 < strata_value[0] or value_0 > strata_value[1] or value_1 < strata_value[0] or value_1 > strata_value[1]:\n",
    "                    return False\n",
    "            else:\n",
    "                is_in_one = False\n",
    "                for b_interval in strata_value:\n",
    "                    if value_0 >= b_interval[0] and value_0 <= b_interval[1] and value_1 >= b_interval[0] and value_1 <= b_interval[1]:\n",
    "                        is_in_one = True\n",
    "                if not is_in_one:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_if_pair_explained_kCAP(pair_,df_,X,dic_treatment_path):\n",
    "    for index, row in df_.iterrows():\n",
    "        rule_explains = get_if_treatment_outcome_pair_in_rule(row,pair_,X,dic_treatment_path)\n",
    "        if rule_explains:\n",
    "            pair_in_strata = get_if_pair_in_strata(row,pair_,X,dic_treatment_path)\n",
    "            if pair_in_strata:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_test = 3000\n",
    "number_explained = 0\n",
    "for pair_ in random.sample(list_pairs,number_test):\n",
    "    if get_if_pair_explained_kCAP(pair_,df_KCAP_rules,X,dic_treatment_path):\n",
    "        number_explained += 1\n",
    "print(number_explained/number_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernier point : robustesse des données\n",
    "\n",
    "Comment varient les règles si on enlève des données pendant l'entrainement ?\n",
    "- facile pour les embeddings\n",
    "- reprendre notebook pour KCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
